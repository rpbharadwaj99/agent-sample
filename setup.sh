#!/bin/bash

# Agent Sample UI - Setup Script
# Run this after cloning the repository

set -e  # Exit on any error

echo "ğŸš€ Agent Sample UI - Setup"
echo "=========================="

# Check prerequisites
echo "ğŸ” Checking prerequisites..."

# Check Node.js
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js is not installed. Please install Node.js 18+ from https://nodejs.org/"
    exit 1
fi
NODE_VERSION=$(node --version)
echo "âœ… Node.js: $NODE_VERSION"

# Check Python
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 is not installed. Please install Python 3.8+ from https://python.org/"
    exit 1
fi
PYTHON_VERSION=$(python3 --version)
echo "âœ… Python: $PYTHON_VERSION"

# Check npm
if ! command -v npm &> /dev/null; then
    echo "âŒ npm is not installed. Please install Node.js with npm."
    exit 1
fi
NPM_VERSION=$(npm --version)
echo "âœ… npm: $NPM_VERSION"

echo ""

# Install Node.js dependencies
echo "ğŸ“¦ Installing Node.js dependencies..."
npm install

# Create Python virtual environment
echo "ğŸ Creating Python virtual environment..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
    echo "âœ… Virtual environment created"
else
    echo "âœ… Virtual environment already exists"
fi

# Install Python dependencies
echo "ğŸ“¦ Installing Python dependencies..."
source venv/bin/activate
pip install -r requirements.txt

# Check if Ollama is installed
echo ""
echo "ğŸ¦™ Checking Ollama installation..."
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is installed"
    
    # Check if Ollama is running
    if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
        echo "âœ… Ollama is running"
        
        # Check if llama3.2 model is available
        if ollama list | grep -q "llama3.2"; then
            echo "âœ… llama3.2 model is available"
        else
            echo "âš ï¸  llama3.2 model not found"
            echo "ğŸ“¥ Pulling llama3.2 model (this may take a few minutes)..."
            ollama pull llama3.2
            echo "âœ… llama3.2 model downloaded"
        fi
    else
        echo "âš ï¸  Ollama is not running"
        echo "ğŸ”§ Please start Ollama in another terminal:"
        echo "   ollama serve"
        echo ""
        echo "ğŸ“¥ Then pull the required model:"
        echo "   ollama pull llama3.2"
    fi
else
    echo "âŒ Ollama is not installed"
    echo "ğŸ“¥ Please install Ollama from: https://ollama.ai"
    echo "ğŸ”§ After installation, run:"
    echo "   ollama serve"
    echo "   ollama pull llama3.2"
fi

echo ""
echo "ğŸ‰ Setup Complete!"
echo ""
echo "ğŸ“‹ What was installed:"
echo "   âœ… Node.js dependencies (lit, @ag-ui/client, vite, etc.)"
echo "   âœ… Python virtual environment (venv/)"
echo "   âœ… Python dependencies (agno, fastapi, uvicorn, etc.)"
echo ""
echo "ğŸš€ Next steps:"
echo "   1. Make sure Ollama is running: ollama serve"
echo "   2. Make sure llama3.2 model is available: ollama pull llama3.2"
echo "   3. Start the project: ./start.sh"
echo "   4. Open http://localhost:3000"
echo ""
echo "ğŸ”§ Useful commands:"
echo "   ./start.sh           # Start both frontend and backend"
echo "   ./check.sh           # Check if everything is running"
echo "   python test-agui.py  # Test the AG-UI protocol"
echo ""